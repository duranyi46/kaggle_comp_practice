{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'int' and 'Categorical'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVehicle_Age\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVehicle_Age\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(new_dtype)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Binning and encoding additional features\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNot_Insured and Damaged\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVehicle_Damage\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPreviously_Insured\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_feat\u001b[39m(df):\n\u001b[0;32m     39\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge_Vehicle_Age\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVehicle_Age\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\deadp\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m method(\u001b[38;5;28mself\u001b[39m, other)\n",
      "File \u001b[1;32mc:\\Users\\deadp\\anaconda3\\Lib\\site-packages\\pandas\\core\\arraylike.py:198\u001b[0m, in \u001b[0;36mOpsMixin.__rsub__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__rsub__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__rsub__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m--> 198\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_arith_method(other, roperator\u001b[38;5;241m.\u001b[39mrsub)\n",
      "File \u001b[1;32mc:\\Users\\deadp\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:5819\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   5817\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_arith_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, op):\n\u001b[0;32m   5818\u001b[0m     \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_for_op(other)\n\u001b[1;32m-> 5819\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m base\u001b[38;5;241m.\u001b[39mIndexOpsMixin\u001b[38;5;241m.\u001b[39m_arith_method(\u001b[38;5;28mself\u001b[39m, other, op)\n",
      "File \u001b[1;32mc:\\Users\\deadp\\anaconda3\\Lib\\site-packages\\pandas\\core\\base.py:1381\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   1378\u001b[0m     rvalues \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(rvalues\u001b[38;5;241m.\u001b[39mstart, rvalues\u001b[38;5;241m.\u001b[39mstop, rvalues\u001b[38;5;241m.\u001b[39mstep)\n\u001b[0;32m   1380\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1381\u001b[0m     result \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39marithmetic_op(lvalues, rvalues, op)\n\u001b[0;32m   1383\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(result, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[1;32mc:\\Users\\deadp\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:275\u001b[0m, in \u001b[0;36marithmetic_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;66;03m# NB: We assume that extract_array and ensure_wrapped_if_datetimelike\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m#  have already been called on `left` and `right`,\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m#  and `maybe_prepare_scalar_for_op` has already been called on `right`\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# We need to special-case datetime64/timedelta64 dtypes (e.g. because numpy\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# casts integer dtypes to timedelta64 when operating with timedelta64 - GH#22390)\u001b[39;00m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    269\u001b[0m     should_extension_dispatch(left, right)\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(right, (Timedelta, BaseOffset, Timestamp))\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;66;03m# Timedelta/Timestamp and other custom scalars are included in the check\u001b[39;00m\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;66;03m# because numexpr will fail on it, see GH#31457\u001b[39;00m\n\u001b[1;32m--> 275\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m op(left, right)\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;66;03m# TODO we should handle EAs consistently and move this check before the if/else\u001b[39;00m\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;66;03m# (https://github.com/pandas-dev/pandas/issues/41165)\u001b[39;00m\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;66;03m# error: Argument 2 to \"_bool_arith_check\" has incompatible type\u001b[39;00m\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;66;03m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[0;32m    281\u001b[0m     _bool_arith_check(op, left, right)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\deadp\\anaconda3\\Lib\\site-packages\\pandas\\core\\roperator.py:15\u001b[0m, in \u001b[0;36mrsub\u001b[1;34m(left, right)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrsub\u001b[39m(left, right):\n\u001b[1;32m---> 15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m right \u001b[38;5;241m-\u001b[39m left\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'int' and 'Categorical'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, RobustScaler, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, roc_curve, auc, ConfusionMatrixDisplay\n",
    "\n",
    "# Load datasets\n",
    "orig = pd.read_csv(\"train.csv\")\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "sample_sub = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "orig_filtered = orig[orig['Response'] == 1]\n",
    "\n",
    "# Merge the filtered orig dataframe with the train dataframe\n",
    "train = pd.concat([train, orig_filtered], axis=0).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Convert less unique columns to category\n",
    "less = [col for col in train.columns if train[col].nunique() < 4 and col in test.columns]\n",
    "for col in less:\n",
    "    train[col] = train[col].astype(\"category\")\n",
    "\n",
    "# Convert 'Vehicle_Age' to ordered categorical\n",
    "from pandas.api.types import CategoricalDtype\n",
    "new_categories = ['< 1 Year', '1-2 Year', '> 2 Years']\n",
    "new_dtype = CategoricalDtype(categories=new_categories, ordered=True)\n",
    "train['Vehicle_Age'] = train['Vehicle_Age'].astype(new_dtype)\n",
    "\n",
    "# Binning and encoding additional features\n",
    "train['Not_Insured and Damaged'] = train['Vehicle_Damage'] * (1 - train['Previously_Insured'])\n",
    "def add_feat(df):\n",
    "    df['Age_Vehicle_Age'] = df['Age'] * df['Vehicle_Age']\n",
    "    df['Age_Annual_Premium'] = df['Age'] * df['Annual_Premium']\n",
    "    df['Vehicle_Damage_Annual_Premium'] = df['Vehicle_Damage'] * df['Annual_Premium']\n",
    "    return df\n",
    "train = add_feat(train)\n",
    "train['Region_8'] = np.where(train['Region_Code'] == 8, 1, 0).astype(np.int8)\n",
    "train['Region_28'] = np.where(train['Region_Code'] == 28, 1, 0).astype(np.int8)\n",
    "train['Channel_26'] = np.where(train['Policy_Sales_Channel'] == 26, 1, 0).astype(np.int8)\n",
    "train['Channel_124'] = np.where(train['Policy_Sales_Channel'] == 124, 1, 0).astype(np.int8)\n",
    "train['Channel_152'] = np.where(train['Policy_Sales_Channel'] == 152, 1, 0).astype(np.int8)\n",
    "\n",
    "# Drop unused columns\n",
    "cols_to_drop = ['id', 'Age', 'Region_Code', 'Policy_Sales_Channel','Vintage','Age_Bin','Policy_Sales_Channel_Bin','Region_Code_Bin','Vintage_Bin']\n",
    "X = train.drop(columns=cols_to_drop + ['Response'], axis=1)\n",
    "y = train['Response']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Define the ColumnTransformer\n",
    "coltrans = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(), ['Driving_License', 'Gender', 'Previously_Insured', 'Vehicle_Damage']),\n",
    "        ('ordinal', OrdinalEncoder(categories=[['< 1 Year', '1-2 Year', '> 2 Years']]), ['Vehicle_Age']),\n",
    "        ('robust', RobustScaler(), ['Annual_Premium']),\n",
    "        ('standard', StandardScaler(), ['Age_Class', 'PSC_Class', 'Vintage_Class', 'Region_Code_Class'])\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Apply transformations\n",
    "X_train_trans = coltrans.fit_transform(X_train)\n",
    "X_val_trans = coltrans.transform(X_val)\n",
    "\n",
    "# Preprocess test data in the same way\n",
    "for col in less:\n",
    "    test[col] = test[col].astype(\"category\")\n",
    "test['Not_Insured and Damaged'] = test['Vehicle_Damage'] * (1 - test['Previously_Insured'])\n",
    "test = add_feat(test)\n",
    "test['Region_8'] = np.where(test['Region_Code'] == 8, 1, 0).astype(np.int8)\n",
    "test['Region_28'] = np.where(test['Region_Code'] == 28, 1, 0).astype(np.int8)\n",
    "test['Channel_26'] = np.where(test['Policy_Sales_Channel'] == 26, 1, 0).astype(np.int8)\n",
    "test['Channel_124'] = np.where(test['Policy_Sales_Channel'] == 124, 1, 0).astype(np.int8)\n",
    "test['Channel_152'] = np.where(test['Policy_Sales_Channel'] == 152, 1, 0).astype(np.int8)\n",
    "\n",
    "# Transform the test data\n",
    "test_trans = coltrans.transform(test.drop(columns=cols_to_drop, axis=1))\n",
    "\n",
    "# Define evaluation function\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_hat_test = model.predict(X_test)\n",
    "    print('             Classification Report')\n",
    "    print('---------------------------------------------')\n",
    "    print(classification_report(y_test, y_hat_test))\n",
    "    fig, axes = plt.subplots(figsize=(12, 8), ncols=2)\n",
    "    cm = ConfusionMatrixDisplay.from_estimator(model, X_test, y_test, normalize='true', cmap='Blues', ax=axes[0])\n",
    "    axes[0].set_title('Confusion Matrix')\n",
    "    y_score = model.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    axes[1].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    axes[1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    axes[1].set_xlim([0.0, 1.0])\n",
    "    axes[1].set_ylim([0.0, 1.05])\n",
    "    axes[1].set_xlabel('False Positive Rate')\n",
    "    axes[1].set_ylabel('True Positive Rate')\n",
    "    axes[1].set_title('ROC-AUC Curve')\n",
    "    axes[1].legend(loc='lower right')\n",
    "    axes[1].grid()\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Define the model and perform grid search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [4, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import rocauc_score\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "model = LGBMClassifier(\n",
    "\n",
    "                        boosting_type = 'gbdt',\n",
    "                        objective = 'binary',\n",
    "                        metric = 'auc',\n",
    "                        verbosity = -1,\n",
    "                        n_estimators = 1000,\n",
    "                        max_depth = 5,\n",
    "                        random_state = 42\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(\n",
    "    X_train_trans,\n",
    "    y_train,\n",
    "    eval_set=[(X_val_trans, y_val)],\n",
    ")\n",
    "\n",
    "y_pred = model.predict(X_val_trans)\n",
    "y_pred_prob = model.predict_proba(X_val_trans)[:,1]\n",
    "auc = rocauc_score(y_val,y_pred_prob)\n",
    "print(f\" AUC: {auc:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model.featureimportances\n",
    "feature_names = coltrans.get_feature_names_out()\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "})\n",
    "\n",
    "\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model, X_val_trans, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model.predict_proba(test_trans)[:, 1] \n",
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub['Response'] = test_preds.astype(np.float32)\n",
    "sample_sub['id'] = sample_sub['id'].astype(np.int32)\n",
    "sample_sub.to_csv('submission3.csv', index=False)\n",
    "sample_sub"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
